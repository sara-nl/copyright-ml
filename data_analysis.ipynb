{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and take a look\n",
    "\n",
    "Let's start by looking at what columns we have, what their data types are and how many null-values there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142130/1094095778.py:1: DtypeWarning: Columns (7,8,10,20,27,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1585585 entries, 0 to 1585584\n",
      "Data columns (total 87 columns):\n",
      " #   Column                         Non-Null Count    Dtype  \n",
      "---  ------                         --------------    -----  \n",
      " 0   PredictionSurfNormalized       40088 non-null    object \n",
      " 1   PredictionToolNormalized       854287 non-null   object \n",
      " 2   FacultyName                    0 non-null        float64\n",
      " 3   CourseName                     1585585 non-null  object \n",
      " 4   PredictionSurf                 40088 non-null    object \n",
      " 5   PredictionInstitution          7309 non-null     object \n",
      " 6   PredictionRemark               30659 non-null    object \n",
      " 7   CorrectDoi                     69 non-null       object \n",
      " 8   CorrectISBN                    62 non-null       object \n",
      " 9   Level2                         1585585 non-null  object \n",
      " 10  Level3                         811897 non-null   object \n",
      " 11  Level4                         0 non-null        float64\n",
      " 12  CourseId                       1585585 non-null  int64  \n",
      " 13  CalculatedReliability          1585585 non-null  int64  \n",
      " 14  AnalyseError                   766946 non-null   object \n",
      " 15  CorrectAnalyseSurf             1585585 non-null  int64  \n",
      " 16  CorrectAnalyseInstitution      1585585 non-null  int64  \n",
      " 17  AnalyseISBN                    1585585 non-null  int64  \n",
      " 18  AnalyseDOI                     1585585 non-null  int64  \n",
      " 19  id                             1585585 non-null  int64  \n",
      " 20  uuid                           1585585 non-null  object \n",
      " 21  url                            1585585 non-null  object \n",
      " 22  filesource                     1585585 non-null  object \n",
      " 23  filestatus                     1585585 non-null  int64  \n",
      " 24  filemimetype                   1585585 non-null  object \n",
      " 25  filename                       1585501 non-null  object \n",
      " 26  filehash                       854275 non-null   object \n",
      " 27  filedate                       1114128 non-null  object \n",
      " 28  lastmodifieddate               997957 non-null   object \n",
      " 29  creator                        825533 non-null   object \n",
      " 30  isfilepublished                1585585 non-null  bool   \n",
      " 31  wordcount                      1585585 non-null  int64  \n",
      " 32  pagecount                      1585585 non-null  int64  \n",
      " 33  filescanresults                1585585 non-null  int64  \n",
      " 34  doi                            55476 non-null    object \n",
      " 35  issn                           0 non-null        float64\n",
      " 36  isbn                           11332 non-null    object \n",
      " 37  author                         517514 non-null   object \n",
      " 38  title                          433596 non-null   object \n",
      " 39  publisher                      6573 non-null     object \n",
      " 40  publicationyear                47922 non-null    float64\n",
      " 41  sourcepagecount                1585585 non-null  int64  \n",
      " 42  sourcewordcount                1585585 non-null  int64  \n",
      " 43  usedpages                      0 non-null        float64\n",
      " 44  filetype                       1585585 non-null  int64  \n",
      " 45  oclcnumber                     1585585 non-null  int64  \n",
      " 46  incollection                   1585585 non-null  bool   \n",
      " 47  userexcludedforscan            1585585 non-null  bool   \n",
      " 48  usedmultiplesources            1585585 non-null  bool   \n",
      " 49  isopenaccesstitle              1585585 non-null  bool   \n",
      " 50  openaccesslink                 18498 non-null    object \n",
      " 51  openaccesscolor                0 non-null        float64\n",
      " 52  filepath                       0 non-null        float64\n",
      " 53  runidentifier                  0 non-null        float64\n",
      " 54  picturecount                   1585585 non-null  int64  \n",
      " 55  prediction                     854287 non-null   object \n",
      " 56  reliability                    1585585 non-null  int64  \n",
      " 57  jstor                          854287 non-null   object \n",
      " 58  always                         854287 non-null   object \n",
      " 59  DOI_in_OA                      854287 non-null   object \n",
      " 60  DOI_no_PPT                     854287 non-null   object \n",
      " 61  PPT_in_name                    854287 non-null   object \n",
      " 62  ppt_creator                    854287 non-null   object \n",
      " 63  wordcount_o                    854287 non-null   object \n",
      " 64  _10_pics_page                  0 non-null        float64\n",
      " 65  Contains_DOI                   854287 non-null   object \n",
      " 66  Contains_ISBN                  854287 non-null   object \n",
      " 67  creator_abbyy                  854287 non-null   object \n",
      " 68  WordsPage350                   854287 non-null   object \n",
      " 69  keyword_creator                854287 non-null   object \n",
      " 70  Words_more_300pp               854287 non-null   object \n",
      " 71  file_ext_mp3_wav               854287 non-null   object \n",
      " 72  file_ext_mp4_mov               854287 non-null   object \n",
      " 73  _10Pagecount50                 854287 non-null   object \n",
      " 74  Contains_copyright             854287 non-null   object \n",
      " 75  Kleiner_10_paginas             854287 non-null   object \n",
      " 76  filename_indicator             854287 non-null   object \n",
      " 77  Contains_sciencemag            854287 non-null   object \n",
      " 78  Pagecount_bigger_50            854287 non-null   object \n",
      " 79  BookAndWords10000              854287 non-null   object \n",
      " 80  Contains_published_in          854287 non-null   object \n",
      " 81  Contains_researchgate          854287 non-null   object \n",
      " 82  Contains_to_appear_in          854287 non-null   object \n",
      " 83  IsJournalWords8000             854287 non-null   object \n",
      " 84  images_same_pagecount          854287 non-null   object \n",
      " 85  Publisher_from_crossref        854287 non-null   object \n",
      " 86  Contains_recommended_citation  854287 non-null   object \n",
      "dtypes: bool(5), float64(9), int64(17), object(56)\n",
      "memory usage: 999.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    './Data/output_SURF.csv',\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7309"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df[\"PredictionInstitution\"].notna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionSurfNormalized</th>\n",
       "      <th>PredictionToolNormalized</th>\n",
       "      <th>FacultyName</th>\n",
       "      <th>CourseName</th>\n",
       "      <th>PredictionSurf</th>\n",
       "      <th>PredictionInstitution</th>\n",
       "      <th>PredictionRemark</th>\n",
       "      <th>CorrectDoi</th>\n",
       "      <th>CorrectISBN</th>\n",
       "      <th>Level2</th>\n",
       "      <th>...</th>\n",
       "      <th>Contains_sciencemag</th>\n",
       "      <th>Pagecount_bigger_50</th>\n",
       "      <th>BookAndWords10000</th>\n",
       "      <th>Contains_published_in</th>\n",
       "      <th>Contains_researchgate</th>\n",
       "      <th>Contains_to_appear_in</th>\n",
       "      <th>IsJournalWords8000</th>\n",
       "      <th>images_same_pagecount</th>\n",
       "      <th>Publisher_from_crossref</th>\n",
       "      <th>Contains_recommended_citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metabolic Consequences of Chronic Diseases wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Nutrition and Health</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Eigen Materiaal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease Ecology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Ecology and Conservation Group</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agrobiodiversity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soil Biology</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Management Skills in Theory &amp; Practice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Learning Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thesis Skills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural Sociology</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PredictionSurfNormalized PredictionToolNormalized  FacultyName  \\\n",
       "0                      NaN                      NaN          NaN   \n",
       "1                      NaN          Eigen Materiaal          NaN   \n",
       "2                      NaN                      NaN          NaN   \n",
       "3                      NaN                      NaN          NaN   \n",
       "4                      NaN                      NaN          NaN   \n",
       "\n",
       "                                          CourseName PredictionSurf  \\\n",
       "0  Metabolic Consequences of Chronic Diseases wit...            NaN   \n",
       "1                                    Disease Ecology            NaN   \n",
       "2                                   Agrobiodiversity            NaN   \n",
       "3             Management Skills in Theory & Practice            NaN   \n",
       "4                                      Thesis Skills            NaN   \n",
       "\n",
       "  PredictionInstitution PredictionRemark CorrectDoi CorrectISBN  \\\n",
       "0                   NaN              NaN        NaN         NaN   \n",
       "1                   NaN              NaN        NaN         NaN   \n",
       "2                   NaN              NaN        NaN         NaN   \n",
       "3                   NaN              NaN        NaN         NaN   \n",
       "4                   NaN              NaN        NaN         NaN   \n",
       "\n",
       "                                    Level2  ... Contains_sciencemag  \\\n",
       "0               Human Nutrition and Health  ...                 NaN   \n",
       "1  Wildlife Ecology and Conservation Group  ...               False   \n",
       "2                             Soil Biology  ...                 NaN   \n",
       "3          Education and Learning Sciences  ...                 NaN   \n",
       "4                          Rural Sociology  ...                 NaN   \n",
       "\n",
       "   Pagecount_bigger_50  BookAndWords10000  Contains_published_in  \\\n",
       "0                  NaN                NaN                    NaN   \n",
       "1                False              False                  False   \n",
       "2                  NaN                NaN                    NaN   \n",
       "3                  NaN                NaN                    NaN   \n",
       "4                  NaN                NaN                    NaN   \n",
       "\n",
       "  Contains_researchgate  Contains_to_appear_in  IsJournalWords8000  \\\n",
       "0                   NaN                    NaN                 NaN   \n",
       "1                 False                  False               False   \n",
       "2                   NaN                    NaN                 NaN   \n",
       "3                   NaN                    NaN                 NaN   \n",
       "4                   NaN                    NaN                 NaN   \n",
       "\n",
       "   images_same_pagecount  Publisher_from_crossref  \\\n",
       "0                    NaN                      NaN   \n",
       "1                  False                    False   \n",
       "2                    NaN                      NaN   \n",
       "3                    NaN                      NaN   \n",
       "4                    NaN                      NaN   \n",
       "\n",
       "   Contains_recommended_citation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns contain only null values and will not be used:\n",
    "\n",
    "<ul>\n",
    "    <li> 'FacultyName'\n",
    "    <li> 'Level4'\n",
    "    <li> 'issn'\n",
    "    <li> 'usedpages'\n",
    "    <li> 'openaccesscolor'\n",
    "    <li> 'filepath'\n",
    "    <li> 'runidentifier'\n",
    "    <li> '_10_pics_page'\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     if df[col].isna().all():\n",
    "#         print(col)\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns concern the predictions and will not be used as input:\n",
    "\n",
    "<ul>\n",
    "    <li> 'PredictionSurf'\n",
    "    <li> 'PredictionInstitution' (ground truth)\n",
    "    <li> 'PredictionRemark'\n",
    "    <li> 'prediction'\n",
    "</ul>\n",
    "\n",
    "The column 'PredictionInstitution' will be used as label, therefore all rows where this column has a null-value will be dropped. The others will be dropped completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PredictionSurf', 'prediction', 'PredictionRemark', 'PredictionSurfNormalized', 'PredictionToolNormalized'], axis=\"columns\", inplace=True)\n",
    "df.dropna(subset=['PredictionInstitution'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns will not be used:\n",
    "\n",
    "<ul>\n",
    "    <li> 'CourseName'\n",
    "    <li> 'CorrectDoi'\n",
    "    <li> 'CorrectISBN'\n",
    "    <li> 'Level2'\n",
    "    <li> 'Level3'\n",
    "    <li> 'CourseId'\n",
    "    <li> 'AnalyseError'\n",
    "    <li> 'CorrectAnalyseSurf'\n",
    "    <li> 'CorrectAnalyseInstitution'\n",
    "    <li> 'AnalyseISBN'\n",
    "    <li> 'AnalyseDOI'\n",
    "    <li> 'id'\n",
    "    <li> 'uuid'\n",
    "    <li> 'url'\n",
    "    <li> 'filesource'\n",
    "    <li> 'filestatus'\n",
    "    <li> 'filename'\n",
    "    <li> 'filehash'\n",
    "    <li> 'filedate'\n",
    "    <li> 'filetype'\n",
    "    <li> 'lastmodifieddate'\n",
    "    <li> 'creator'\n",
    "    <li> 'filescanresults'\n",
    "    <li> 'doi'\n",
    "    <li> 'isbn'\n",
    "    <li> 'author'\n",
    "    <li> 'title'\n",
    "    <li> 'publisher'\n",
    "    <li> 'publicationyear'\n",
    "    <li> 'sourcepagecount'\n",
    "    <li> 'sourcewordcount'\n",
    "    <li> 'oclcnumber'\n",
    "    <li> 'openaccesslink'\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_cols = ['CourseName', 'CorrectDoi', 'CorrectISBN', \n",
    "'Level2', 'Level3', 'CourseId', 'AnalyseError', 'CorrectAnalyseSurf', \n",
    "'CorrectAnalyseInstitution', 'AnalyseISBN', 'AnalyseDOI', 'id', \n",
    "'uuid', 'url', 'filesource', 'filestatus', 'filename', 'filehash', \n",
    "'filedate', 'filetype', 'lastmodifieddate', 'creator', 'filescanresults', 'doi', 'isbn', \n",
    "'author', 'title', 'publisher', 'publicationyear', 'sourcepagecount', \n",
    "'sourcewordcount', 'oclcnumber', 'openaccesslink']\n",
    "\n",
    "df.drop(identifier_cols, axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take another look at our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7309 entries, 386 to 1585415\n",
      "Data columns (total 41 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   PredictionInstitution          7309 non-null   object\n",
      " 1   CalculatedReliability          7309 non-null   int64 \n",
      " 2   filemimetype                   7309 non-null   object\n",
      " 3   isfilepublished                7309 non-null   bool  \n",
      " 4   wordcount                      7309 non-null   int64 \n",
      " 5   pagecount                      7309 non-null   int64 \n",
      " 6   incollection                   7309 non-null   bool  \n",
      " 7   userexcludedforscan            7309 non-null   bool  \n",
      " 8   usedmultiplesources            7309 non-null   bool  \n",
      " 9   isopenaccesstitle              7309 non-null   bool  \n",
      " 10  picturecount                   7309 non-null   int64 \n",
      " 11  reliability                    7309 non-null   int64 \n",
      " 12  jstor                          7309 non-null   object\n",
      " 13  always                         7309 non-null   object\n",
      " 14  DOI_in_OA                      7309 non-null   object\n",
      " 15  DOI_no_PPT                     7309 non-null   object\n",
      " 16  PPT_in_name                    7309 non-null   object\n",
      " 17  ppt_creator                    7309 non-null   object\n",
      " 18  wordcount_o                    7309 non-null   object\n",
      " 19  Contains_DOI                   7309 non-null   object\n",
      " 20  Contains_ISBN                  7309 non-null   object\n",
      " 21  creator_abbyy                  7309 non-null   object\n",
      " 22  WordsPage350                   7309 non-null   object\n",
      " 23  keyword_creator                7309 non-null   object\n",
      " 24  Words_more_300pp               7309 non-null   object\n",
      " 25  file_ext_mp3_wav               7309 non-null   object\n",
      " 26  file_ext_mp4_mov               7309 non-null   object\n",
      " 27  _10Pagecount50                 7309 non-null   object\n",
      " 28  Contains_copyright             7309 non-null   object\n",
      " 29  Kleiner_10_paginas             7309 non-null   object\n",
      " 30  filename_indicator             7309 non-null   object\n",
      " 31  Contains_sciencemag            7309 non-null   object\n",
      " 32  Pagecount_bigger_50            7309 non-null   object\n",
      " 33  BookAndWords10000              7309 non-null   object\n",
      " 34  Contains_published_in          7309 non-null   object\n",
      " 35  Contains_researchgate          7309 non-null   object\n",
      " 36  Contains_to_appear_in          7309 non-null   object\n",
      " 37  IsJournalWords8000             7309 non-null   object\n",
      " 38  images_same_pagecount          7309 non-null   object\n",
      " 39  Publisher_from_crossref        7309 non-null   object\n",
      " 40  Contains_recommended_citation  7309 non-null   object\n",
      "dtypes: bool(5), int64(5), object(31)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a separate look at columns with dtype object (or bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype == 'bool']\n",
    "len(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns with dtype object contain boolean values. We will change these to 0s and 1s and change their dtype to int. We also fill in the null values with 0s, so that we don't have to drop those datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_cols:\n",
    "    if set(df[col].dropna().unique()) == {False, True}:\n",
    "        df.loc[df[col] == True, col] = 1\n",
    "        df.loc[df[col] == False, col] = 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].astype(\"int\")\n",
    "    elif len(set(df[col].dropna().unique())) == 1:\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a profiling report\n",
    "\n",
    "Uncomment and run this cell to get a pandas profiling report. This will show nicely which features are correlated, amongst other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df.reset_index(drop=True), title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"pandas_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates\n",
    "\n",
    "Making changes to the data, particularly dropping columns, has introduced duplicate rows. These need to be dropped to prevent a bias when training our model. This leaves us with 766 unique datapoints, that each have 26 features and a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 766 entries, 0 to 765\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   PredictionInstitution  766 non-null    object\n",
      " 1   CalculatedReliability  766 non-null    int64 \n",
      " 2   isfilepublished        766 non-null    int64 \n",
      " 3   wordcount              766 non-null    int64 \n",
      " 4   pagecount              766 non-null    int64 \n",
      " 5   isopenaccesstitle      766 non-null    int64 \n",
      " 6   picturecount           766 non-null    int64 \n",
      " 7   reliability            766 non-null    int64 \n",
      " 8   DOI_in_OA              766 non-null    int64 \n",
      " 9   DOI_no_PPT             766 non-null    int64 \n",
      " 10  PPT_in_name            766 non-null    int64 \n",
      " 11  ppt_creator            766 non-null    int64 \n",
      " 12  wordcount_o            766 non-null    int64 \n",
      " 13  Contains_DOI           766 non-null    int64 \n",
      " 14  Contains_ISBN          766 non-null    int64 \n",
      " 15  creator_abbyy          766 non-null    int64 \n",
      " 16  WordsPage350           766 non-null    int64 \n",
      " 17  keyword_creator        766 non-null    int64 \n",
      " 18  Words_more_300pp       766 non-null    int64 \n",
      " 19  _10Pagecount50         766 non-null    int64 \n",
      " 20  Contains_copyright     766 non-null    int64 \n",
      " 21  Kleiner_10_paginas     766 non-null    int64 \n",
      " 22  filename_indicator     766 non-null    int64 \n",
      " 23  Pagecount_bigger_50    766 non-null    int64 \n",
      " 24  BookAndWords10000      766 non-null    int64 \n",
      " 25  Contains_published_in  766 non-null    int64 \n",
      " 26  images_same_pagecount  766 non-null    int64 \n",
      "dtypes: int64(26), object(1)\n",
      "memory usage: 161.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels' support\n",
    "\n",
    "Let's take a look at the support of each label, i.e., how often does each label occur in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen materiaal - titelindicatie  332\n",
      "korte overname                    232\n",
      "middellange overname               55\n",
      "lange overname                     25\n",
      "mogelijk licentie                   1\n",
      "open access                        14\n",
      "eigen materiaal - powerpoint       92\n",
      "overname met licentie               1\n",
      "eigen materiaal -overig             2\n",
      "eigen materiaal - overig           12\n"
     ]
    }
   ],
   "source": [
    "labels = df[\"PredictionInstitution\"]\n",
    "unique_labels = labels.unique()\n",
    "\n",
    "for label in unique_labels:\n",
    "    print('{:<32}  {:>3}'.format(label, (labels == label).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate and drop\n",
    "\n",
    "Some of these labels can be aggregated. Some others simpy do not have enough samples and will be dropped. This leaves us with 6 classes that have 14 - 346 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"PredictionInstitution\"] == \"eigen materiaal -overig\", \"PredictionInstitution\"] = \"eigen materiaal - overig\"\n",
    "df.loc[df[\"PredictionInstitution\"] == \"eigen materiaal - titelindicatie\", \"PredictionInstitution\"] = \"eigen materiaal - overig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen materiaal - overig          346\n",
      "korte overname                    232\n",
      "middellange overname               55\n",
      "lange overname                     25\n",
      "open access                        14\n",
      "eigen materiaal - powerpoint       92\n"
     ]
    }
   ],
   "source": [
    "df_label_subset = df[df.PredictionInstitution != \"mogelijk licentie\"]\n",
    "df_label_subset = df_label_subset[df_label_subset.PredictionInstitution != \"overname met licentie\"]\n",
    "\n",
    "\n",
    "labels = df_label_subset[\"PredictionInstitution\"]\n",
    "unique_labels = labels.unique()\n",
    "\n",
    "for label in unique_labels:\n",
    "    print('{:<32}  {:>3}'.format(label, (labels == label).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "We split the data frame into x and encoded y, which we transform to numpy arrays. We also create a simple train/test split and a stratified K-folds cross-validator, making 5 datasplits that each preserve the percentage of samples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_label_subset.drop(\"PredictionInstitution\", axis=\"columns\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_label_subset[\"PredictionInstitution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "\n",
    "There are many features with high correlation. XGBoost is not so sensitive to this. Another benefit of XGBoost is the ability to get feature importances quite easily.\n",
    "\n",
    "#### Train using a simple data split\n",
    "\n",
    "This makes is easy to use sklearn's classification report functionality, so we can very quickly evaluate how the model performs per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "    eigen materiaal - overig       0.93      0.97      0.95        69\n",
      "eigen materiaal - powerpoint       0.79      0.83      0.81        18\n",
      "              korte overname       1.00      0.96      0.98        46\n",
      "              lange overname       1.00      0.20      0.33         5\n",
      "        middellange overname       0.77      0.91      0.83        11\n",
      "                 open access       0.33      0.33      0.33         3\n",
      "\n",
      "                    accuracy                           0.91       152\n",
      "                   macro avg       0.80      0.70      0.71       152\n",
      "                weighted avg       0.91      0.91      0.90       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using K-fold\n",
    "\n",
    "This gives us a more reliable accuracy and F1-score, as we eliminate the risk of testing on a particularly favorable or unfavorable test partition.\n",
    "\n",
    "(It is also useful for hyperparameter optimization, should we choose to add that in later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.9541279669762641\n",
      "F1:  0.8733134565069441\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    predictions = xgb_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(\"Acc: \", accuracy_scores/5)\n",
    "print(\"F1: \", f1_scores/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP FIVE\n",
      "---------------------------------\n",
      "_10Pagecount50      0.40114375948905945\n",
      "ppt_creator         0.15439678728580475\n",
      "pagecount           0.1494448482990265\n",
      "Words_more_300pp    0.1224411353468895\n",
      "DOI_no_PPT          0.057369474321603775\n",
      "\n",
      "\n",
      "\n",
      "ZERO SCORE\n",
      "---------------------------------\n",
      "isopenaccesstitle\n",
      "DOI_in_OA\n",
      "PPT_in_name\n",
      "wordcount_o\n",
      "Contains_DOI\n",
      "creator_abbyy\n",
      "Contains_copyright\n",
      "Kleiner_10_paginas\n",
      "Pagecount_bigger_50\n",
      "BookAndWords10000\n",
      "Contains_published_in\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.drop(\"PredictionInstitution\", axis=\"columns\").columns.to_numpy()\n",
    "feature_importance_scores = xgb_model.feature_importances_\n",
    "\n",
    "top_five_indices = np.argpartition(feature_importance_scores, (-5, -1))[-5:]\n",
    "top_five_scores = feature_importance_scores[top_five_indices][::-1]\n",
    "top_five_names = feature_names[top_five_indices][::-1]\n",
    "\n",
    "print(\"TOP FIVE\\n---------------------------------\")\n",
    "for name, score in zip(top_five_names, top_five_scores):\n",
    "    print('{:<18}  {:>3}'.format(name, score))\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\nZERO SCORE\\n---------------------------------\")\n",
    "zero_score_indices = np.argwhere(feature_importance_scores == 0).flatten()\n",
    "zero_score_features = feature_names[zero_score_indices]\n",
    "\n",
    "for feature in zero_score_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Since logistic regression is quite similar to what the current tool does, much more so than XGBoost, let's give that a try as well. In order to use logistic regression, we will have to standardize our data first.\n",
    "\n",
    "This model also performs well, however (when using K-fold) it is not quite as good as XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "    eigen materiaal - overig       0.99      1.00      0.99        75\n",
      "eigen materiaal - powerpoint       1.00      0.95      0.98        21\n",
      "              korte overname       0.96      1.00      0.98        47\n",
      "              lange overname       1.00      1.00      1.00         3\n",
      "        middellange overname       1.00      0.67      0.80         6\n",
      "                 open access       1.00      1.00      1.00         1\n",
      "\n",
      "                    accuracy                           0.98       153\n",
      "                   macro avg       0.99      0.94      0.96       153\n",
      "                weighted avg       0.98      0.98      0.98       153\n",
      "\n",
      "0.9266597867217061\n",
      "0.8465778961543876\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = lr_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(scaled_x, y):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    predictions = lr_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/5)\n",
    "print(f1_scores/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054e63ccd0723eba59e4e775f028e662383a4d3e051ddb13b43bfc67a74f1731"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
