{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and take a look\n",
    "\n",
    "Let's start by looking at what columns we have, what their data types are and how many null-values there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50760/2396107422.py:1: DtypeWarning: Columns (7,8,10,20,27,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1585585 entries, 0 to 1585584\n",
      "Data columns (total 87 columns):\n",
      " #   Column                         Non-Null Count    Dtype  \n",
      "---  ------                         --------------    -----  \n",
      " 0   PredictionSurfNormalized       40088 non-null    object \n",
      " 1   PredictionToolNormalized       854287 non-null   object \n",
      " 2   FacultyName                    0 non-null        float64\n",
      " 3   CourseName                     1585585 non-null  object \n",
      " 4   PredictionSurf                 40088 non-null    object \n",
      " 5   PredictionInstitution          7309 non-null     object \n",
      " 6   PredictionRemark               30659 non-null    object \n",
      " 7   CorrectDoi                     69 non-null       object \n",
      " 8   CorrectISBN                    62 non-null       object \n",
      " 9   Level2                         1585585 non-null  object \n",
      " 10  Level3                         811897 non-null   object \n",
      " 11  Level4                         0 non-null        float64\n",
      " 12  CourseId                       1585585 non-null  int64  \n",
      " 13  CalculatedReliability          1585585 non-null  int64  \n",
      " 14  AnalyseError                   766946 non-null   object \n",
      " 15  CorrectAnalyseSurf             1585585 non-null  int64  \n",
      " 16  CorrectAnalyseInstitution      1585585 non-null  int64  \n",
      " 17  AnalyseISBN                    1585585 non-null  int64  \n",
      " 18  AnalyseDOI                     1585585 non-null  int64  \n",
      " 19  id                             1585585 non-null  int64  \n",
      " 20  uuid                           1585585 non-null  object \n",
      " 21  url                            1585585 non-null  object \n",
      " 22  filesource                     1585585 non-null  object \n",
      " 23  filestatus                     1585585 non-null  int64  \n",
      " 24  filemimetype                   1585585 non-null  object \n",
      " 25  filename                       1585501 non-null  object \n",
      " 26  filehash                       854275 non-null   object \n",
      " 27  filedate                       1114128 non-null  object \n",
      " 28  lastmodifieddate               997957 non-null   object \n",
      " 29  creator                        825533 non-null   object \n",
      " 30  isfilepublished                1585585 non-null  bool   \n",
      " 31  wordcount                      1585585 non-null  int64  \n",
      " 32  pagecount                      1585585 non-null  int64  \n",
      " 33  filescanresults                1585585 non-null  int64  \n",
      " 34  doi                            55476 non-null    object \n",
      " 35  issn                           0 non-null        float64\n",
      " 36  isbn                           11332 non-null    object \n",
      " 37  author                         517514 non-null   object \n",
      " 38  title                          433596 non-null   object \n",
      " 39  publisher                      6573 non-null     object \n",
      " 40  publicationyear                47922 non-null    float64\n",
      " 41  sourcepagecount                1585585 non-null  int64  \n",
      " 42  sourcewordcount                1585585 non-null  int64  \n",
      " 43  usedpages                      0 non-null        float64\n",
      " 44  filetype                       1585585 non-null  int64  \n",
      " 45  oclcnumber                     1585585 non-null  int64  \n",
      " 46  incollection                   1585585 non-null  bool   \n",
      " 47  userexcludedforscan            1585585 non-null  bool   \n",
      " 48  usedmultiplesources            1585585 non-null  bool   \n",
      " 49  isopenaccesstitle              1585585 non-null  bool   \n",
      " 50  openaccesslink                 18498 non-null    object \n",
      " 51  openaccesscolor                0 non-null        float64\n",
      " 52  filepath                       0 non-null        float64\n",
      " 53  runidentifier                  0 non-null        float64\n",
      " 54  picturecount                   1585585 non-null  int64  \n",
      " 55  prediction                     854287 non-null   object \n",
      " 56  reliability                    1585585 non-null  int64  \n",
      " 57  jstor                          854287 non-null   object \n",
      " 58  always                         854287 non-null   object \n",
      " 59  DOI_in_OA                      854287 non-null   object \n",
      " 60  DOI_no_PPT                     854287 non-null   object \n",
      " 61  PPT_in_name                    854287 non-null   object \n",
      " 62  ppt_creator                    854287 non-null   object \n",
      " 63  wordcount_o                    854287 non-null   object \n",
      " 64  _10_pics_page                  0 non-null        float64\n",
      " 65  Contains_DOI                   854287 non-null   object \n",
      " 66  Contains_ISBN                  854287 non-null   object \n",
      " 67  creator_abbyy                  854287 non-null   object \n",
      " 68  WordsPage350                   854287 non-null   object \n",
      " 69  keyword_creator                854287 non-null   object \n",
      " 70  Words_more_300pp               854287 non-null   object \n",
      " 71  file_ext_mp3_wav               854287 non-null   object \n",
      " 72  file_ext_mp4_mov               854287 non-null   object \n",
      " 73  _10Pagecount50                 854287 non-null   object \n",
      " 74  Contains_copyright             854287 non-null   object \n",
      " 75  Kleiner_10_paginas             854287 non-null   object \n",
      " 76  filename_indicator             854287 non-null   object \n",
      " 77  Contains_sciencemag            854287 non-null   object \n",
      " 78  Pagecount_bigger_50            854287 non-null   object \n",
      " 79  BookAndWords10000              854287 non-null   object \n",
      " 80  Contains_published_in          854287 non-null   object \n",
      " 81  Contains_researchgate          854287 non-null   object \n",
      " 82  Contains_to_appear_in          854287 non-null   object \n",
      " 83  IsJournalWords8000             854287 non-null   object \n",
      " 84  images_same_pagecount          854287 non-null   object \n",
      " 85  Publisher_from_crossref        854287 non-null   object \n",
      " 86  Contains_recommended_citation  854287 non-null   object \n",
      "dtypes: bool(5), float64(9), int64(17), object(56)\n",
      "memory usage: 999.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    './Data/output_SURF.csv',\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionSurfNormalized</th>\n",
       "      <th>PredictionToolNormalized</th>\n",
       "      <th>FacultyName</th>\n",
       "      <th>CourseName</th>\n",
       "      <th>PredictionSurf</th>\n",
       "      <th>PredictionInstitution</th>\n",
       "      <th>PredictionRemark</th>\n",
       "      <th>CorrectDoi</th>\n",
       "      <th>CorrectISBN</th>\n",
       "      <th>Level2</th>\n",
       "      <th>...</th>\n",
       "      <th>Contains_sciencemag</th>\n",
       "      <th>Pagecount_bigger_50</th>\n",
       "      <th>BookAndWords10000</th>\n",
       "      <th>Contains_published_in</th>\n",
       "      <th>Contains_researchgate</th>\n",
       "      <th>Contains_to_appear_in</th>\n",
       "      <th>IsJournalWords8000</th>\n",
       "      <th>images_same_pagecount</th>\n",
       "      <th>Publisher_from_crossref</th>\n",
       "      <th>Contains_recommended_citation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metabolic Consequences of Chronic Diseases wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Nutrition and Health</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Eigen Materiaal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disease Ecology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wildlife Ecology and Conservation Group</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agrobiodiversity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soil Biology</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Management Skills in Theory &amp; Practice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Learning Sciences</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thesis Skills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rural Sociology</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PredictionSurfNormalized PredictionToolNormalized  FacultyName  \\\n",
       "0                      NaN                      NaN          NaN   \n",
       "1                      NaN          Eigen Materiaal          NaN   \n",
       "2                      NaN                      NaN          NaN   \n",
       "3                      NaN                      NaN          NaN   \n",
       "4                      NaN                      NaN          NaN   \n",
       "\n",
       "                                          CourseName PredictionSurf  \\\n",
       "0  Metabolic Consequences of Chronic Diseases wit...            NaN   \n",
       "1                                    Disease Ecology            NaN   \n",
       "2                                   Agrobiodiversity            NaN   \n",
       "3             Management Skills in Theory & Practice            NaN   \n",
       "4                                      Thesis Skills            NaN   \n",
       "\n",
       "  PredictionInstitution PredictionRemark CorrectDoi CorrectISBN  \\\n",
       "0                   NaN              NaN        NaN         NaN   \n",
       "1                   NaN              NaN        NaN         NaN   \n",
       "2                   NaN              NaN        NaN         NaN   \n",
       "3                   NaN              NaN        NaN         NaN   \n",
       "4                   NaN              NaN        NaN         NaN   \n",
       "\n",
       "                                    Level2  ... Contains_sciencemag  \\\n",
       "0               Human Nutrition and Health  ...                 NaN   \n",
       "1  Wildlife Ecology and Conservation Group  ...               False   \n",
       "2                             Soil Biology  ...                 NaN   \n",
       "3          Education and Learning Sciences  ...                 NaN   \n",
       "4                          Rural Sociology  ...                 NaN   \n",
       "\n",
       "   Pagecount_bigger_50  BookAndWords10000  Contains_published_in  \\\n",
       "0                  NaN                NaN                    NaN   \n",
       "1                False              False                  False   \n",
       "2                  NaN                NaN                    NaN   \n",
       "3                  NaN                NaN                    NaN   \n",
       "4                  NaN                NaN                    NaN   \n",
       "\n",
       "  Contains_researchgate  Contains_to_appear_in  IsJournalWords8000  \\\n",
       "0                   NaN                    NaN                 NaN   \n",
       "1                 False                  False               False   \n",
       "2                   NaN                    NaN                 NaN   \n",
       "3                   NaN                    NaN                 NaN   \n",
       "4                   NaN                    NaN                 NaN   \n",
       "\n",
       "   images_same_pagecount  Publisher_from_crossref  \\\n",
       "0                    NaN                      NaN   \n",
       "1                  False                    False   \n",
       "2                    NaN                      NaN   \n",
       "3                    NaN                      NaN   \n",
       "4                    NaN                      NaN   \n",
       "\n",
       "   Contains_recommended_citation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns contain only null values and will not be used:\n",
    "\n",
    "<ul>\n",
    "    <li> 'FacultyName'\n",
    "    <li> 'Level4'\n",
    "    <li> 'issn'\n",
    "    <li> 'usedpages'\n",
    "    <li> 'openaccesscolor'\n",
    "    <li> 'filepath'\n",
    "    <li> 'runidentifier'\n",
    "    <li> '_10_pics_page'\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FacultyName\n",
      "Level4\n",
      "issn\n",
      "usedpages\n",
      "openaccesscolor\n",
      "filepath\n",
      "runidentifier\n",
      "_10_pics_page\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].isna().all():\n",
    "        print(col)\n",
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns concern the predictions and will not be used as input:\n",
    "\n",
    "<ul>\n",
    "    <li> 'PredictionSurf'\n",
    "    <li> 'PredictionInstitution' (ground truth)\n",
    "    <li> 'PredictionRemark'\n",
    "    <li> 'prediction'\n",
    "</ul>\n",
    "\n",
    "The column 'PredictionInstitution' will be used as label, therefore all rows where this column has a null-value will be dropped. The others will be dropped completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PredictionSurf', 'prediction', 'PredictionRemark', 'PredictionSurfNormalized', 'PredictionToolNormalized'], axis=\"columns\", inplace=True)\n",
    "df.dropna(subset=['PredictionInstitution'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns seem to contain identifiers and the like:\n",
    "\n",
    "<ul>\n",
    "    <li> 'FacultyName'\n",
    "    <li> 'CourseName'\n",
    "    <li> 'CourseName'\n",
    "    <li> 'CorrectDoi'\n",
    "    <li> 'CorrectISBN'\n",
    "    <li> 'AnalyseError'\n",
    "    <li> 'CorrectAnalyseSurf'\n",
    "    <li> 'CorrectAnalyseInstitution'\n",
    "    <li> 'AnalyseISBN'\n",
    "    <li> 'AnalyseDOI'\n",
    "    <li> 'id'\n",
    "    <li> 'uuid'\n",
    "    <li> 'url'\n",
    "    <li> 'filesource'\n",
    "    <li> 'filestatus'\n",
    "    <li> 'filemimetype'\n",
    "    <li> 'filename'\n",
    "    <li> 'filehash'\n",
    "    <li> 'filedate'\n",
    "    <li> 'lastmodifieddate'\n",
    "    <li> 'creator'\n",
    "    <li> 'isfilepublished'\n",
    "    <li> 'filescanresults'\n",
    "    <li> 'doi'\n",
    "    <li> 'isbn'\n",
    "    <li> 'author'\n",
    "    <li> 'title'\n",
    "    <li> 'publicationyear'\n",
    "    <li> 'oclcnumber'\n",
    "</ul>\n",
    "\n",
    "These columns will not be used.\n",
    "\n",
    "#### I PLAN TO TAKE A CLOSER LOOK AT AT LEAST SOME OF THESE, like title which might become a useful feature with the application of NLP, or 'CorrectAnalyse' columns, which may tell us something about the tool's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_cols = ['CourseName', 'CorrectDoi', 'CorrectISBN',\n",
    "'AnalyseError', 'CorrectAnalyseSurf', 'CorrectAnalyseInstitution',\n",
    "'AnalyseISBN', 'AnalyseDOI', 'id', 'uuid', 'url', 'filesource',\n",
    "'filestatus', 'filemimetype', 'filename', 'filehash', 'filedate',\n",
    "'lastmodifieddate', 'creator', 'isfilepublished', 'filescanresults',\n",
    "'doi', 'isbn', 'author', 'title', 'publicationyear', 'oclcnumber']\n",
    "\n",
    "df.drop(identifier_cols, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take another look at our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7309 entries, 386 to 1585415\n",
      "Data columns (total 47 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   PredictionInstitution          7309 non-null   object\n",
      " 1   Level2                         7309 non-null   object\n",
      " 2   Level3                         3483 non-null   object\n",
      " 3   CourseId                       7309 non-null   int64 \n",
      " 4   CalculatedReliability          7309 non-null   int64 \n",
      " 5   wordcount                      7309 non-null   int64 \n",
      " 6   pagecount                      7309 non-null   int64 \n",
      " 7   publisher                      57 non-null     object\n",
      " 8   sourcepagecount                7309 non-null   int64 \n",
      " 9   sourcewordcount                7309 non-null   int64 \n",
      " 10  filetype                       7309 non-null   int64 \n",
      " 11  incollection                   7309 non-null   bool  \n",
      " 12  userexcludedforscan            7309 non-null   bool  \n",
      " 13  usedmultiplesources            7309 non-null   bool  \n",
      " 14  isopenaccesstitle              7309 non-null   bool  \n",
      " 15  openaccesslink                 6 non-null      object\n",
      " 16  picturecount                   7309 non-null   int64 \n",
      " 17  reliability                    7309 non-null   int64 \n",
      " 18  jstor                          7309 non-null   object\n",
      " 19  always                         7309 non-null   object\n",
      " 20  DOI_in_OA                      7309 non-null   object\n",
      " 21  DOI_no_PPT                     7309 non-null   object\n",
      " 22  PPT_in_name                    7309 non-null   object\n",
      " 23  ppt_creator                    7309 non-null   object\n",
      " 24  wordcount_o                    7309 non-null   object\n",
      " 25  Contains_DOI                   7309 non-null   object\n",
      " 26  Contains_ISBN                  7309 non-null   object\n",
      " 27  creator_abbyy                  7309 non-null   object\n",
      " 28  WordsPage350                   7309 non-null   object\n",
      " 29  keyword_creator                7309 non-null   object\n",
      " 30  Words_more_300pp               7309 non-null   object\n",
      " 31  file_ext_mp3_wav               7309 non-null   object\n",
      " 32  file_ext_mp4_mov               7309 non-null   object\n",
      " 33  _10Pagecount50                 7309 non-null   object\n",
      " 34  Contains_copyright             7309 non-null   object\n",
      " 35  Kleiner_10_paginas             7309 non-null   object\n",
      " 36  filename_indicator             7309 non-null   object\n",
      " 37  Contains_sciencemag            7309 non-null   object\n",
      " 38  Pagecount_bigger_50            7309 non-null   object\n",
      " 39  BookAndWords10000              7309 non-null   object\n",
      " 40  Contains_published_in          7309 non-null   object\n",
      " 41  Contains_researchgate          7309 non-null   object\n",
      " 42  Contains_to_appear_in          7309 non-null   object\n",
      " 43  IsJournalWords8000             7309 non-null   object\n",
      " 44  images_same_pagecount          7309 non-null   object\n",
      " 45  Publisher_from_crossref        7309 non-null   object\n",
      " 46  Contains_recommended_citation  7309 non-null   object\n",
      "dtypes: bool(4), int64(9), object(34)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a separate look at columns with dtype object (or bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype == 'bool']\n",
    "len(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns with dtype object contain boolean values. We will change these to 0s and 1s and change their dtype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_cols:\n",
    "    if set(df[col].dropna().unique()) == {False, True}:\n",
    "        df.loc[df[col] == True, col] = 1\n",
    "        df.loc[df[col] == False, col] = 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].astype(\"int\")\n",
    "    elif len(set(df[col].dropna().unique())) == 1:\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a profiling report\n",
    "\n",
    "Uncomment and run this cell to get a pandas profiling report. This will show nicely which features are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas-profiling[notebook] in ./venv/lib/python3.8/site-packages (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy<1.10,>=1.4.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.9.1)\n",
      "Requirement already satisfied, skipping upgrade: missingno<0.6,>=0.4.2 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML<6.1,>=5.0.0 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (6.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<2.29,>=2.24.0 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (2.28.1)\n",
      "Requirement already satisfied, skipping upgrade: pydantic<1.10,>=1.8.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.9.2)\n",
      "Requirement already satisfied, skipping upgrade: jinja2<3.2,>=2.11.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: seaborn<0.12,>=0.10.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<4.65,>=4.48.2 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib<3.6,>=3.2 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (3.5.3)\n",
      "Requirement already satisfied, skipping upgrade: tangled-up-in-unicode==0.2.0 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pandas!=1.4.0,<1.5,>1.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.4.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.24,>=1.16.0 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.23.2)\n",
      "Requirement already satisfied, skipping upgrade: multimethod<1.9,>=1.4 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.8)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels<0.14,>=0.13.2 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: htmlmin==0.1.12 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.1.12)\n",
      "Requirement already satisfied, skipping upgrade: joblib~=1.1.0 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: visions[type_image_path]==0.7.5 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: phik<0.13,>=0.11.1 in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (0.12.2)\n",
      "Requirement already satisfied, skipping upgrade: ipywidgets>=7.5.1; extra == \"notebook\" in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (8.0.2)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.3; extra == \"notebook\" in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (4.11.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4; extra == \"notebook\" in ./venv/lib/python3.8/site-packages (from pandas-profiling[notebook]) (7.3.5)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (3.3)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (1.26.12)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<3,>=2 in ./venv/lib/python3.8/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests<2.29,>=2.24.0->pandas-profiling[notebook]) (2022.6.15.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in ./venv/lib/python3.8/site-packages (from pydantic<1.10,>=1.8.1->pandas-profiling[notebook]) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in ./venv/lib/python3.8/site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling[notebook]) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (3.0.9)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (9.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (4.37.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (1.4.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in ./venv/lib/python3.8/site-packages (from pandas!=1.4.0,<1.5,>1.1->pandas-profiling[notebook]) (2022.2.1)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.5.2 in ./venv/lib/python3.8/site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling[notebook]) (0.5.2)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.4 in ./venv/lib/python3.8/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (2.8.6)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=19.3.0 in ./venv/lib/python3.8/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (22.1.0)\n",
      "Requirement already satisfied, skipping upgrade: imagehash; extra == \"type_image_path\" in ./venv/lib/python3.8/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=6.1.0 in ./venv/lib/python3.8/site-packages (from ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (8.5.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in ./venv/lib/python3.8/site-packages (from ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (6.15.2)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-widgets~=3.0 in ./venv/lib/python3.8/site-packages (from ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in ./venv/lib/python3.8/site-packages (from ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (5.3.0)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=4.0 in ./venv/lib/python3.8/site-packages (from ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (4.0.3)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints in ./venv/lib/python3.8/site-packages (from jupyter-client>=5.3.4; extra == \"notebook\"->pandas-profiling[notebook]) (0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=23.0 in ./venv/lib/python3.8/site-packages (from jupyter-client>=5.3.4; extra == \"notebook\"->pandas-profiling[notebook]) (23.2.1)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio>=1.5.4 in ./venv/lib/python3.8/site-packages (from jupyter-client>=5.3.4; extra == \"notebook\"->pandas-profiling[notebook]) (1.5.5)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=6.2 in ./venv/lib/python3.8/site-packages (from jupyter-client>=5.3.4; extra == \"notebook\"->pandas-profiling[notebook]) (6.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in ./venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib<3.6,>=3.2->pandas-profiling[notebook]) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets in ./venv/lib/python3.8/site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.7.5->pandas-profiling[notebook]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pygments>=2.4.0 in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (2.13.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.16 in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.18.1)\n",
      "Requirement already satisfied, skipping upgrade: stack-data in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit<3.1.0,>3.0.1 in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (3.0.31)\n",
      "Requirement already satisfied, skipping upgrade: pexpect>4.3; sys_platform != \"win32\" in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib-inline in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.1.6)\n",
      "Requirement already satisfied, skipping upgrade: backcall in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: decorator in ./venv/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (5.1.1)\n",
      "Requirement already satisfied, skipping upgrade: debugpy>=1.0 in ./venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: psutil in ./venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (5.9.2)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.9.0,>=0.8.0 in ./venv/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: asttokens in ./venv/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (2.0.8)\n",
      "Requirement already satisfied, skipping upgrade: executing in ./venv/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pure-eval in ./venv/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in ./venv/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in ./venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets>=7.5.1; extra == \"notebook\"->pandas-profiling[notebook]) (0.7.0)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12da8b39da740bea53eae90d53e833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivian/Documents/copyRIGHT/venv/lib/python3.8/site-packages/pandas_profiling/model/correlations.py:55: UserWarning: There was an attempt to calculate the cramers correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"cramers\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/pandas-profiling/issues\n",
      "(include the error message: 'No data; `observed` has size 0.')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f72d8f5b3d945eb9586f09f2ff8bfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fef9caf73b549e187851f2961092d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6c8b42b68d475fb45a20ca00636582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df.reset_index(drop=True), title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"pandas_report2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant values\n",
    "\n",
    "There are 2 columns with a constant value: 'sourcepagecount' and 'sourcewordcount'. These columns will be dropped.\n",
    "\n",
    "#### QUESTION: What are these columns? How does it relate to 'pagecount' and 'wordcount'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"sourcepagecount\", \"sourcewordcount\", \"incollection\", \"userexcludedforscan\", \"usedmultiplesources\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last columns of dtype object\n",
    "\n",
    "The last three columns of dtype object consist of 2 non-boolean features and 1 column with the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "len(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name: PredictionInstitution\n",
      "number of unique values: 10\n",
      "unique values: ['eigen materiaal - titelindicatie' 'korte overname'\n",
      " 'middellange overname' 'lange overname' 'mogelijk licentie' 'open access'\n",
      " 'eigen materiaal - powerpoint' 'overname met licentie'\n",
      " 'eigen materiaal -overig' 'eigen materiaal - overig']\n",
      "number of null values: 0\n",
      "----------------------\n",
      "column name: Level2\n",
      "number of unique values: 140\n",
      "unique values: ['Education and Learning Sciences' 'Meteorology and Air Quality'\n",
      " 'Amsterdam Institute for Advanced Metropolitan Solutions'\n",
      " 'Business Economics' 'Soil Biology' 'Food Chemistry'\n",
      " 'Biobased Chemistry and Technology' 'Consumption and Healthy Lifestyles'\n",
      " 'Development Economics' 'Experimental Zoology' 'Law Group'\n",
      " 'Marine Animal Ecology' 'Operations Research and Logistics'\n",
      " 'Physical Chemistry and Soft Matter'\n",
      " 'Communication Philosophy and Technology' 'Crop Systems Analysis'\n",
      " 'Environmental Policy' 'Forest and Nature Conservation Policy'\n",
      " 'Health and Society' 'Bionanotechnology' 'Bioprocess Engineering'\n",
      " 'Farming Systems Ecology' 'Cultural Geography'\n",
      " 'Human Nutrition and Health' 'Landscape Architecture' 'Plant Breeding'\n",
      " 'Rural Sociology' 'Sociology of Development and Change'\n",
      " 'Systems and Synthetic Biology' 'Urban Economics'\n",
      " 'Water Resources Management' 'Animal Sciences' 'Biochemistry'\n",
      " 'Farm Technology' 'Hydrology and Quantitative Water Management'\n",
      " 'Research Methodology' 'Food Microbiology'\n",
      " 'Public Administration and Policy' 'Entomology'\n",
      " 'Forest Ecology and Forest Management'\n",
      " 'Physics and Physical Chemistry of Foods'\n",
      " 'Geo-information Science and Remote Sensing'\n",
      " 'Plant Ecology and Nature Conservation' 'Rural and Environmental History'\n",
      " 'Wageningen University' 'Agricultural Economics and Rural Policy'\n",
      " 'Biosystematics' 'Environmental Systems Analysis'\n",
      " 'Food Process Engineering' 'Land Use Planning'\n",
      " 'Marketing and Consumer Behaviour' 'Water Systems and Global Change'\n",
      " 'Adaptation Physiology' 'Environmental Technology'\n",
      " 'Quantitative Veterinary Epidemiology' 'Genetics' 'Plant Sciences'\n",
      " 'Food Quality and Design'\n",
      " 'Wetsus, European Centre of Excellence for Sustainable Water Technology'\n",
      " 'Human and Animal Physiology' 'Nutrition and Health'\n",
      " 'Business Management and Organisation'\n",
      " 'Mathematical and Statistical Methods' 'Industrial Design Engineering'\n",
      " 'Architecture and the Built Environment' 'University Corporate Office'\n",
      " 'Civil Engineering and Geosciences'\n",
      " 'Electrical Engineering, Mathematics and Computer Science'\n",
      " 'Aerospace Engineering' 'Technology, Policy and Management'\n",
      " 'Applied Sciences' 'Mechanical, Maritime and Materials Engineering'\n",
      " 'Testcourses instructors' '{}' 'B-TN: Technische Natuurkunde'\n",
      " 'Testcourses project members' 'Practice courses' 'BMS niet-OSIRIS'\n",
      " 'M-EE: Electrical Engineering'\n",
      " 'M-PSTS: Philosophy of Science, Technology and Society'\n",
      " 'M-AP: Applied Physics' 'M-TM: Technical Medicine'\n",
      " 'M-CME: Construction Management and Engineering' 'B-PSY: Psychology'\n",
      " 'B-COM: Communication Science'\n",
      " 'EEMCS: Electrical Engineering, Mathematics and Computer Science'\n",
      " 'B-GZW: Gezondheidswetenschappen' 'B-CSE: Chemical Engineering'\n",
      " 'B-BMT: Biomedische Technologie' 'M-BME: Biomedical Engineering'\n",
      " 'M-AM: Applied Mathematics' 'B-EE: Electrical Engineering'\n",
      " 'BMS: Behavioural, Management and Social Sciences'\n",
      " 'B-CE: Civil Engineering' 'M-PSY: Psychology'\n",
      " 'M-CHE: Chemical Science & Engineering' 'B-ME: Mechanical Engineering'\n",
      " 'ET: Engineering Technology' 'TNW niet-OSIRIS' 'CELT'\n",
      " 'M-ME: Mechanical Engineering' 'M-BA: Business Administration'\n",
      " 'B-IBA: International Business Administration'\n",
      " 'B-BIT: Business Information Technology' 'M-SC: Systems and Control'\n",
      " 'M-CEM: Civil Engineering and Management' 'B-AT: Advanced Technology'\n",
      " 'B-CREA: Creative Technology' 'Pre-U' 'EEMCS niet-OSIRIS'\n",
      " 'UT Algemeen - niet OSIRIS' 'ET niet-OSIRIS' 'B-AM: Applied Mathematics'\n",
      " 'M-EST: Educational Science and Technology'\n",
      " 'M-ECB: Educatie en Communicatie in de Bètawetenschappen'\n",
      " 'M-SET: Sustainable Energy Technology' 'M-PA: Public Administration'\n",
      " 'M-HS: Health Sciences' 'PLD niet-OSIRIS' 'B-TG: Technische Geneeskunde'\n",
      " 'M-ES: European Studies' 'B-MST: Management, Society and Technology'\n",
      " 'MRM' 'B-ID: Industrial Design Engineering' 'M-CS: Computer Science'\n",
      " 'M-GEO-WO: Geo-information Science and Earth Observation' 'UTLC'\n",
      " 'ATLAS niet-OSIRIS' 'ITC non-regular courses' 'MPM'\n",
      " 'B-ATLAS: Technology and Liberal Arts & Sciences'\n",
      " 'M-ITECH: Interaction Technology'\n",
      " 'B-IEM: Industrial Engineering and Management'\n",
      " 'B-ME-VU: Mechanical Engineering - Bachelor Amsterdam (VU-UT)'\n",
      " 'M-IDE: Industrial Design Engineering' 'M-NT: Nanotechnology'\n",
      " 'B-CS: Technical Computer Science' 'CELT-Trainingen'\n",
      " 'M-SE: Spatial Engineering'\n",
      " 'M-IEM: Industrial Engineering and Management']\n",
      "number of null values: 0\n",
      "----------------------\n",
      "column name: Level3\n",
      "number of unique values: 61\n",
      "unique values: ['2019-2020' '2020-2021' '2021-2022' '2022-2023' '2016/17 Q3' nan\n",
      " '2017/18 Q1' '2017/18 Q2' '2017/18 Q3' '2017/18 Q4' '2018/19 Q1'\n",
      " '2018/19 Q4' '2018/19 Q3' '2018/19 Q2' '2019/20 Q1' '2019/20 Q4'\n",
      " '2019/20 Q3' '2019/20 Q2' '2020/21 Q1' '2020/21 Q3' '2020/21'\n",
      " '2020/21 Q4' '2021/22 Q1' '2021/22 Q2' '2021/22 Q4' 'Sandbox Courses'\n",
      " '2020/21 Q2' '2021/22 Q3' '2021/22' '2017/18' '2018/19' '2019/20' '2016'\n",
      " 'Default term' '2017-2A' '2020-1A' '2017-1B' '2017-1A' '2017-2B'\n",
      " '2018-JAAR' '2018-1B' '2018-1A' '2018-2A' '2018-2B' '2019-1B' '2019-1A'\n",
      " '2019-SEM 1' '2019-JAAR' '2019-2A' '2019-2B' '2020-JAAR' '2020-1B'\n",
      " '2020-SEM 1' '2020-2A' '2020-2B' '2020-SEM 2' '2021-1A' '2021-1B'\n",
      " '2021-JAAR' '2021-2A' '2021-SEM 2']\n",
      "number of null values: 3826\n",
      "----------------------\n",
      "column name: publisher\n",
      "number of unique values: 15\n",
      "unique values: [nan 'TU Delft, Heritage & Architecture' 'TU Delft'\n",
      " 'TU Delft - Heritage & Architecture' 'Cultural Heritage Agency'\n",
      " 'Routledge' 'Ios Press' 'Princeton Architectural Press'\n",
      " 'Taylor & Francis' 'Penguin Books' 'Birkhäuser' 'John Wiley & Sons'\n",
      " 'Wiley' 'Rockport Publishers' 'World Intellectual Property Organization']\n",
      "number of null values: 7252\n",
      "----------------------\n",
      "column name: openaccesslink\n",
      "number of unique values: 3\n",
      "unique values: [nan\n",
      " 'https://pure.rug.nl/ws/files/81733365/Understanding_Customer_Experience_Throughout_the_Customer_Journey.pdf'\n",
      " 'https://academic.oup.com/hmg/article-pdf/13/10/993/1685422/ddh119.pdf']\n",
      "number of null values: 7303\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for col in object_cols:\n",
    "    print(f\"column name: {col}\")\n",
    "    print(f\"number of unique values: {len(df[col].unique())}\")\n",
    "    print(f\"unique values: {df[col].unique()}\")\n",
    "    print(f\"number of null values: {df[col].isna().sum()}\")\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop openaccesslink\n",
    "\n",
    "The 'openaccesslink' feature has 15 unique values, which are uniformly distributed and only once or twice each. This feature has 98% missing values; whether this value is missing highly correlates with the value of 'isopenaccesstitle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints that are open access titles:\t\t6.\n",
      "Number of open access titles that have an open access link:\t6.\n",
      "==========================================================================\n",
      "Number of datapoints that are NOT open access titles:\t\t7303.\n",
      "Number of non open access titles that have an open access link:\t0.\n"
     ]
    }
   ],
   "source": [
    "oa = df.loc[df[\"isopenaccesstitle\"] == 1]\n",
    "print(f\"Number of datapoints that are open access titles:\\t\\t{len(oa)}.\\nNumber of open access titles that have an open access link:\\t{oa['openaccesslink'].notna().sum()}.\")\n",
    "\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "not_oa = df.loc[df[\"isopenaccesstitle\"] == 0]\n",
    "print(f\"Number of datapoints that are NOT open access titles:\\t\\t{len(not_oa)}.\\nNumber of non open access titles that have an open access link:\\t{not_oa['openaccesslink'].notna().sum()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"openaccesslink\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop publisher\n",
    "\n",
    "The 'publisher' feature is highly correlated with many features, such as wordcount, contains_researchgate, Words_more_300pp and several others. It also has 93% missing values and 33 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"publisher\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now, drop level2, level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Level2\", \"Level3\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"isopenaccesstitle\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5285 entries, 0 to 5284\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   PredictionInstitution  5285 non-null   object\n",
      " 1   CourseId               5285 non-null   int64 \n",
      " 2   CalculatedReliability  5285 non-null   int64 \n",
      " 3   wordcount              5285 non-null   int64 \n",
      " 4   pagecount              5285 non-null   int64 \n",
      " 5   filetype               5285 non-null   int64 \n",
      " 6   isopenaccesstitle      5285 non-null   int64 \n",
      " 7   picturecount           5285 non-null   int64 \n",
      " 8   reliability            5285 non-null   int64 \n",
      " 9   DOI_in_OA              5285 non-null   int64 \n",
      " 10  DOI_no_PPT             5285 non-null   int64 \n",
      " 11  PPT_in_name            5285 non-null   int64 \n",
      " 12  ppt_creator            5285 non-null   int64 \n",
      " 13  wordcount_o            5285 non-null   int64 \n",
      " 14  Contains_DOI           5285 non-null   int64 \n",
      " 15  Contains_ISBN          5285 non-null   int64 \n",
      " 16  creator_abbyy          5285 non-null   int64 \n",
      " 17  WordsPage350           5285 non-null   int64 \n",
      " 18  keyword_creator        5285 non-null   int64 \n",
      " 19  Words_more_300pp       5285 non-null   int64 \n",
      " 20  _10Pagecount50         5285 non-null   int64 \n",
      " 21  Contains_copyright     5285 non-null   int64 \n",
      " 22  Kleiner_10_paginas     5285 non-null   int64 \n",
      " 23  filename_indicator     5285 non-null   int64 \n",
      " 24  Pagecount_bigger_50    5285 non-null   int64 \n",
      " 25  BookAndWords10000      5285 non-null   int64 \n",
      " 26  Contains_published_in  5285 non-null   int64 \n",
      " 27  images_same_pagecount  5285 non-null   int64 \n",
      "dtypes: int64(27), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels' support\n",
    "\n",
    "We lost many entries, mostly because they had no value for 'PredictionInstitution', which is our ground truth. Let's take a look at the support of each label, i.e., how often does each label occur in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5285"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen materiaal - titelindicatie  2902\n",
      "korte overname                    1797\n",
      "middellange overname              262\n",
      "lange overname                     37\n",
      "mogelijk licentie                   1\n",
      "open access                        47\n",
      "eigen materiaal - powerpoint      171\n",
      "overname met licentie               2\n",
      "eigen materiaal -overig            31\n",
      "eigen materiaal - overig           35\n"
     ]
    }
   ],
   "source": [
    "labels = df[\"PredictionInstitution\"]\n",
    "unique_labels = labels.unique()\n",
    "\n",
    "for label in unique_labels:\n",
    "    print('{:<32}  {:>3}'.format(label, (labels == label).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: Difference overname open access and open access? zelfde!!   eigen materiaal ook op een hoop (behalve powerpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"PredictionInstitution\"] == \"eigen materiaal -overig\", \"PredictionInstitution\"] = \"eigen materiaal - overig\"\n",
    "df.loc[df[\"PredictionInstitution\"] == \"eigen materiaal - titelindicatie\", \"PredictionInstitution\"] = \"eigen materiaal - overig\"\n",
    "df.loc[df[\"PredictionInstitution\"] == \"eigen materiaal - titelindicatie\", \"PredictionInstitution\"] = \"eigen materiaal - overig\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have enough examples of each class. Let's see what happens if we drop columns with 1 or 2 samples and train only on labels we have more examples of. We also change the label 'overname middellang' to 'middellange overname', since this was probably a labeling error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen materiaal - overig          2968\n",
      "korte overname                    1797\n",
      "middellange overname              262\n",
      "lange overname                     37\n",
      "open access                        47\n",
      "eigen materiaal - powerpoint      171\n"
     ]
    }
   ],
   "source": [
    "df_label_subset = df[df.PredictionInstitution != \"mogelijk licentie\"]\n",
    "df_label_subset = df_label_subset[df_label_subset.PredictionInstitution != \"overname met licentie\"]\n",
    "\n",
    "\n",
    "labels = df_label_subset[\"PredictionInstitution\"]\n",
    "unique_labels = labels.unique()\n",
    "\n",
    "for label in unique_labels:\n",
    "    print('{:<32}  {:>3}'.format(label, (labels == label).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5282, 27)\n",
      "[[112771     62      0      2      0      0      2      2      0      0\n",
      "       0      0      1      0      0      0      0      0      0      0\n",
      "       0      1      0      0      0      0      1]\n",
      " [112771     60      0     18      0      0     18      2      0      0\n",
      "       0      0      1      0      0      0      0      0      0      1\n",
      "       0      0      0      0      0      0      1]\n",
      " [112771     75      0     20      0      0     20      0      0      0\n",
      "       0      0      1      0      0      0      0      0      0      1\n",
      "       0      0      1      0      0      0      1]]\n"
     ]
    }
   ],
   "source": [
    "x = df_label_subset.drop(\"PredictionInstitution\", axis=\"columns\").to_numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5282,)\n",
      "[0 2 2]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(df_label_subset[\"PredictionInstitution\"])\n",
    "\n",
    "print(y.shape)\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "\n",
    "### High correlation\n",
    "\n",
    "There are many features with high correlation. Since tree-based models are not so sensitive to this, let's train XGBoost on our data. This model achieves both accuracy and F1 score of 0.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4225\n",
      "1057\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "    eigen materiaal - overig       1.00      1.00      1.00       602\n",
      "eigen materiaal - powerpoint       1.00      0.97      0.99        37\n",
      "              korte overname       1.00      0.99      1.00       359\n",
      "              lange overname       1.00      0.75      0.86         4\n",
      "        middellange overname       1.00      1.00      1.00        45\n",
      "                 open access       0.91      1.00      0.95        10\n",
      "\n",
      "                    accuracy                           1.00      1057\n",
      "                   macro avg       0.98      0.95      0.97      1057\n",
      "                weighted avg       1.00      1.00      1.00      1057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels' support\n",
    "\n",
    "We don't have enough examples of each class. In an attempt to combat this, we will add some datapoints to our training data that do not have a value for 'PredictionInstitution', but DO have a value for 'prediction'. We also process it the same way we processed the rest of the data above, by removing the same columns etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\n",
    "    './outputSURF-AI-testset.csv',\n",
    "    sep=';'\n",
    ")\n",
    "\n",
    "df2.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df2.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "df2 = df2[df2['PredictionInstitution'].isna()]\n",
    "\n",
    "df2.drop(['PredictionSurf', 'PredictionInstitution', 'PredictionRemark'], axis=\"columns\", inplace=True)\n",
    "df2.dropna(subset=['prediction'], inplace=True)\n",
    "\n",
    "drop_cols = ['FacultyName', 'CourseName', 'CorrectDoi', 'CorrectISBN',\n",
    "'AnalyseError', 'CorrectAnalyseSurf', 'CorrectAnalyseInstitution',\n",
    "'AnalyseISBN', 'AnalyseDOI', 'id', 'uuid', 'url', 'filesource',\n",
    "'filestatus', 'filemimetype', 'filename', 'filehash', 'filedate',\n",
    "'lastmodifieddate', 'creator', 'isfilepublished', 'filescanresults',\n",
    "'doi', 'isbn', 'author', 'title', 'publicationyear',\n",
    "'filetype', 'oclcnumber', 'sourcepagecount', 'sourcewordcount', 'publisher', 'openaccesslink', 'Contains_sciencemag', 'creator_abbyy']\n",
    "\n",
    "df2.drop(drop_cols, axis=\"columns\", inplace=True)\n",
    "\n",
    "object_cols = [col for col in df2.columns if df2[col].dtype == 'object']\n",
    "\n",
    "for col in object_cols:\n",
    "    if set(df2[col].dropna().unique()) == {False, True}:\n",
    "        df2.loc[df2[col] == True, col] = 1\n",
    "        df2.loc[df2[col] == False, col] = 0\n",
    "        df2[col] = df2[col].fillna(0)\n",
    "        df2[col] = df2[col].astype(\"int\")\n",
    "    elif len(set(df2[col].dropna().unique())) == 1:\n",
    "        df2.drop(col, axis=1, inplace=True)\n",
    "\n",
    "df2.dropna(inplace=True)\n",
    "df2.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df2.drop(\"prediction\", axis=\"columns\").to_numpy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df2[\"prediction\"])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x\n",
    "y_test = y\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to train set\n",
    "\n",
    "Instead of treating the data with 'prediction' as its label as the whole training set, let's split the data with 'PredictionInstitution' and add 'prediction' data to the train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\n",
    "    './outputSURF-AI-testset.csv',\n",
    "    sep=';'\n",
    ")\n",
    "\n",
    "df3.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df3.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "df3.drop(['PredictionSurf', 'prediction', 'PredictionRemark'], axis=\"columns\", inplace=True)\n",
    "df3.dropna(subset=['PredictionInstitution'], inplace=True)\n",
    "\n",
    "drop_cols = ['FacultyName', 'CourseName', 'CorrectDoi', 'CorrectISBN',\n",
    "'AnalyseError', 'CorrectAnalyseSurf', 'CorrectAnalyseInstitution',\n",
    "'AnalyseISBN', 'AnalyseDOI', 'id', 'uuid', 'url', 'filesource',\n",
    "'filestatus', 'filemimetype', 'filename', 'filehash', 'filedate',\n",
    "'lastmodifieddate', 'creator', 'isfilepublished', 'filescanresults',\n",
    "'doi', 'isbn', 'author', 'title', 'publicationyear',\n",
    "'filetype', 'oclcnumber', 'sourcepagecount', 'sourcewordcount', 'publisher', 'openaccesslink', 'Contains_sciencemag', 'creator_abbyy']\n",
    "\n",
    "df3.drop(drop_cols, axis=\"columns\", inplace=True)\n",
    "\n",
    "object_cols = [col for col in df3.columns if df3[col].dtype == 'object']\n",
    "\n",
    "for col in object_cols:\n",
    "    if set(df3[col].dropna().unique()) == {False, True}:\n",
    "        df3.loc[df3[col] == True, col] = 1\n",
    "        df3.loc[df3[col] == False, col] = 0\n",
    "        df3[col] = df3[col].fillna(0)\n",
    "        df3[col] = df3[col].astype(\"int\")\n",
    "    elif len(set(df3[col].dropna().unique())) == 1:\n",
    "        df3.drop(col, axis=1, inplace=True)\n",
    "\n",
    "df3.dropna(inplace=True)\n",
    "df3.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3[\"PredictionInstitution\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df3.drop(\"PredictionInstitution\", axis=\"columns\").to_numpy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df3[\"PredictionInstitution\"])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df2.drop(\"prediction\", axis=\"columns\").to_numpy()\n",
    "y2 = label_encoder.transform(df2[\"prediction\"])\n",
    "\n",
    "x_train_augmented = np.vstack((x_train, x2))\n",
    "y_train_augmented = np.concatenate((y_train, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still underrepresented labels, though it's less than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(y_test):\n",
    "    print(i, (y_train_augmented == i).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.inverse_transform([8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train_augmented, y_train_augmented, labels=np.unique(y_train))\n",
    "\n",
    "predictions = xgb_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With K-fold\n",
    "\n",
    "Use K-fold to confirm that the accuracy and F1 is actually that high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    predictions = xgb_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative classifiers\n",
    "\n",
    "### Train another model, an SVC, to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(scaled_x, y):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    svc_model = SVC()\n",
    "    svc_model.fit(x_train, y_train)\n",
    "    predictions = svc_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    predictions = rf_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(scaled_x, y):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    predictions = lr_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "XGBoost has another benefit: it is straightforward to retrieve feature importance scores. Let's take a look at those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df.drop(\"prediction\", axis=\"columns\").columns.to_numpy()\n",
    "feature_importance_scores = xgb_model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_indices = np.argpartition(feature_importance_scores, (-5, -1))[-5:]\n",
    "top_five_scores = feature_importance_scores[top_five_indices][::-1]\n",
    "top_five_names = feature_names[top_five_indices][::-1]\n",
    "\n",
    "for name, score in zip(top_five_names, top_five_scores):\n",
    "    print(f\"{name},   {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score is zero\n",
    "\n",
    "Some of the features have importance scores of 0. When we leave them out, we get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_score_indices = np.argwhere(feature_importance_scores == 0).flatten()\n",
    "zero_score_features = feature_names[zero_score_indices]\n",
    "\n",
    "for feature in zero_score_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = list(zero_score_features)\n",
    "features_to_remove.append(\"prediction\")\n",
    "\n",
    "x = df.drop(features_to_remove, axis=\"columns\").to_numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_model.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054e63ccd0723eba59e4e775f028e662383a4d3e051ddb13b43bfc67a74f1731"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
