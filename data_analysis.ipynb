{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and take a look\n",
    "\n",
    "Let's start by looking at what columns we have, what their data types are and how many null-values there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1601 entries, 0 to 1600\n",
      "Data columns (total 80 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   FacultyName                    1600 non-null   object \n",
      " 1   CourseName                     1600 non-null   object \n",
      " 2   PredictionSurf                 1195 non-null   object \n",
      " 3   PredictionInstitution          876 non-null    object \n",
      " 4   PredictionRemark               360 non-null    object \n",
      " 5   CorrectDoi                     69 non-null     object \n",
      " 6   CorrectISBN                    71 non-null     object \n",
      " 7   AnalyseError                   385 non-null    object \n",
      " 8   CorrectAnalyseSurf             1601 non-null   int64  \n",
      " 9   CorrectAnalyseInstitution      1601 non-null   int64  \n",
      " 10  AnalyseISBN                    1600 non-null   float64\n",
      " 11  AnalyseDOI                     1600 non-null   float64\n",
      " 12  id                             1600 non-null   float64\n",
      " 13  uuid                           1600 non-null   object \n",
      " 14  url                            1600 non-null   object \n",
      " 15  filesource                     1600 non-null   object \n",
      " 16  filestatus                     1600 non-null   float64\n",
      " 17  filemimetype                   1600 non-null   object \n",
      " 18  filename                       1600 non-null   object \n",
      " 19  filehash                       1289 non-null   object \n",
      " 20  filedate                       1599 non-null   object \n",
      " 21  lastmodifieddate               749 non-null    object \n",
      " 22  creator                        713 non-null    object \n",
      " 23  isfilepublished                1597 non-null   object \n",
      " 24  wordcount                      1597 non-null   float64\n",
      " 25  pagecount                      1597 non-null   float64\n",
      " 26  filescanresults                1597 non-null   float64\n",
      " 27  doi                            192 non-null    object \n",
      " 28  issn                           0 non-null      float64\n",
      " 29  isbn                           92 non-null     object \n",
      " 30  author                         353 non-null    object \n",
      " 31  title                          348 non-null    object \n",
      " 32  publisher                      71 non-null     object \n",
      " 33  publicationyear                163 non-null    float64\n",
      " 34  sourcepagecount                1589 non-null   float64\n",
      " 35  sourcewordcount                1589 non-null   float64\n",
      " 36  usedpages                      0 non-null      float64\n",
      " 37  filetype                       1589 non-null   float64\n",
      " 38  oclcnumber                     1589 non-null   float64\n",
      " 39  incollection                   1589 non-null   object \n",
      " 40  userexcludedforscan            1589 non-null   object \n",
      " 41  usedmultiplesources            1589 non-null   object \n",
      " 42  isopenaccesstitle              1589 non-null   object \n",
      " 43  openaccesslink                 62 non-null     object \n",
      " 44  filepath                       0 non-null      float64\n",
      " 45  runidentifier                  0 non-null      float64\n",
      " 46  picturecount                   1589 non-null   float64\n",
      " 47  prediction                     1280 non-null   object \n",
      " 48  reliability                    1589 non-null   float64\n",
      " 49  jstor                          1280 non-null   object \n",
      " 50  always                         1280 non-null   object \n",
      " 51  DOI_in_OA                      1280 non-null   object \n",
      " 52  DOI_no_PPT                     1280 non-null   object \n",
      " 53  PPT_in_name                    1280 non-null   object \n",
      " 54  ppt_creator                    1280 non-null   object \n",
      " 55  wordcount_o                    1280 non-null   object \n",
      " 56  _10_pics_page                  0 non-null      float64\n",
      " 57  Contains_DOI                   1280 non-null   object \n",
      " 58  Contains_ISBN                  1280 non-null   object \n",
      " 59  creator_abbyy                  1280 non-null   object \n",
      " 60  WordsPage350                   1280 non-null   object \n",
      " 61  keyword_creator                1280 non-null   object \n",
      " 62  Words_more_300pp               1280 non-null   object \n",
      " 63  file_ext_mp3_wav               1280 non-null   object \n",
      " 64  file_ext_mp4_mov               1280 non-null   object \n",
      " 65  _10Pagecount50                 1280 non-null   object \n",
      " 66  Contains_copyright             1280 non-null   object \n",
      " 67  Kleiner_10_paginas             1280 non-null   object \n",
      " 68  filename_indicator             1280 non-null   object \n",
      " 69  Contains_sciencemag            1280 non-null   object \n",
      " 70  Pagecount_bigger_50            1280 non-null   object \n",
      " 71  BookAndWords10000              1280 non-null   object \n",
      " 72  Contains_published_in          1280 non-null   object \n",
      " 73  Contains_researchgate          1280 non-null   object \n",
      " 74  Contains_to_appear_in          1280 non-null   object \n",
      " 75  IsJournalWords8000             1280 non-null   object \n",
      " 76  images_same_pagecount          1280 non-null   object \n",
      " 77  Publisher_from_crossref        1280 non-null   object \n",
      " 78  Contains_recommended_citation  1280 non-null   object \n",
      " 79  Kolom1                         0 non-null      float64\n",
      "dtypes: float64(20), int64(2), object(58)\n",
      "memory usage: 1000.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    './outputSURF-AI-testset.csv',\n",
    "    sep=';'\n",
    ")\n",
    "\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns contain only null values and will not be used:\n",
    "\n",
    "<ul>\n",
    "    <li> 'issn'\n",
    "    <li> 'usedpages'\n",
    "    <li> 'filepath'\n",
    "    <li> 'runidentifier'\n",
    "    <li> '_10_pics_page'\n",
    "    <li> 'Kolom1'\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns concern the predictions and will not be used as input:\n",
    "\n",
    "<ul>\n",
    "    <li> 'PredictionSurf'\n",
    "    <li> 'PredictionInstitution' (ground truth)\n",
    "    <li> 'PredictionRemark'\n",
    "    <li> 'prediction'\n",
    "</ul>\n",
    "\n",
    "The column 'prediction' will be used as label, therefore all rows where this column has a null-value will be dropped. The other of these columns will be dropped completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PredictionSurf', 'PredictionInstitution', 'PredictionRemark'], axis=\"columns\", inplace=True)\n",
    "df.dropna(subset=['prediction'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following columns seem to contain identifiers and the like:\n",
    "\n",
    "<ul>\n",
    "    <li> 'FacultyName'\n",
    "    <li> 'CourseName'\n",
    "    <li> 'CourseName'\n",
    "    <li> 'CorrectDoi'\n",
    "    <li> 'CorrectISBN'\n",
    "    <li> 'AnalyseError'\n",
    "    <li> 'CorrectAnalyseSurf'\n",
    "    <li> 'CorrectAnalyseInstitution'\n",
    "    <li> 'AnalyseISBN'\n",
    "    <li> 'CorrectAnalyseInstitution'\n",
    "    <li> 'AnalyseDOI'\n",
    "    <li> 'id'\n",
    "    <li> 'uuid'\n",
    "    <li> 'url'\n",
    "    <li> 'filesource'\n",
    "    <li> 'filestatus'\n",
    "    <li> 'filemimetype'\n",
    "    <li> 'filename'\n",
    "    <li> 'filehash'\n",
    "    <li> 'filedate'\n",
    "    <li> 'lastmodifieddate'\n",
    "    <li> 'creator'\n",
    "    <li> 'isfilepublished'\n",
    "    <li> 'filescanresults'\n",
    "    <li> 'doi'\n",
    "    <li> 'isbn'\n",
    "    <li> 'author'\n",
    "    <li> 'title'\n",
    "    <li> 'publicationyear'\n",
    "    <li> 'filetype'\n",
    "    <li> 'oclcnumber'\n",
    "</ul>\n",
    "\n",
    "These columns will not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_cols = ['FacultyName', 'CourseName', 'CorrectDoi', 'CorrectISBN',\n",
    "'AnalyseError', 'CorrectAnalyseSurf', 'CorrectAnalyseInstitution',\n",
    "'AnalyseISBN', 'AnalyseDOI', 'id', 'uuid', 'url', 'filesource',\n",
    "'filestatus', 'filemimetype', 'filename', 'filehash', 'filedate',\n",
    "'lastmodifieddate', 'creator', 'isfilepublished', 'filescanresults',\n",
    "'doi', 'isbn', 'author', 'title', 'publicationyear',\n",
    "'filetype', 'oclcnumber']\n",
    "\n",
    "df.drop(identifier_cols, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some columns only have one possible value\n",
    "\n",
    "These columns can not be used to distinguish between datapoints and will therefore not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sourcepagecount\t\t\t[0.]\n",
      "sourcewordcount\t\t\t[0.]\n",
      "userexcludedforscan\t\t\t[False]\n",
      "usedmultiplesources\t\t\t[False]\n",
      "always\t\t\t[True]\n",
      "file_ext_mp3_wav\t\t\t[False]\n",
      "file_ext_mp4_mov\t\t\t[False]\n",
      "IsJournalWords8000\t\t\t[False]\n",
      "Publisher_from_crossref\t\t\t[False]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        print(f\"{col}\\t\\t\\t{df[col].unique()}\")\n",
    "        df.drop(col, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take another look at our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1280 entries, 0 to 1599\n",
      "Data columns (total 33 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   wordcount                      1280 non-null   float64\n",
      " 1   pagecount                      1280 non-null   float64\n",
      " 2   publisher                      71 non-null     object \n",
      " 3   incollection                   1280 non-null   object \n",
      " 4   isopenaccesstitle              1280 non-null   object \n",
      " 5   openaccesslink                 62 non-null     object \n",
      " 6   picturecount                   1280 non-null   float64\n",
      " 7   prediction                     1280 non-null   object \n",
      " 8   reliability                    1280 non-null   float64\n",
      " 9   jstor                          1280 non-null   object \n",
      " 10  DOI_in_OA                      1280 non-null   object \n",
      " 11  DOI_no_PPT                     1280 non-null   object \n",
      " 12  PPT_in_name                    1280 non-null   object \n",
      " 13  ppt_creator                    1280 non-null   object \n",
      " 14  wordcount_o                    1280 non-null   object \n",
      " 15  Contains_DOI                   1280 non-null   object \n",
      " 16  Contains_ISBN                  1280 non-null   object \n",
      " 17  creator_abbyy                  1280 non-null   object \n",
      " 18  WordsPage350                   1280 non-null   object \n",
      " 19  keyword_creator                1280 non-null   object \n",
      " 20  Words_more_300pp               1280 non-null   object \n",
      " 21  _10Pagecount50                 1280 non-null   object \n",
      " 22  Contains_copyright             1280 non-null   object \n",
      " 23  Kleiner_10_paginas             1280 non-null   object \n",
      " 24  filename_indicator             1280 non-null   object \n",
      " 25  Contains_sciencemag            1280 non-null   object \n",
      " 26  Pagecount_bigger_50            1280 non-null   object \n",
      " 27  BookAndWords10000              1280 non-null   object \n",
      " 28  Contains_published_in          1280 non-null   object \n",
      " 29  Contains_researchgate          1280 non-null   object \n",
      " 30  Contains_to_appear_in          1280 non-null   object \n",
      " 31  images_same_pagecount          1280 non-null   object \n",
      " 32  Contains_recommended_citation  1280 non-null   object \n",
      "dtypes: float64(4), object(29)\n",
      "memory usage: 340.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a separate look at columns with dtype object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "len(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most columns with dtype object contain boolean values. We will change these to 0s and 1s and change their dtype to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in object_cols:\n",
    "    if set(df[col].dropna().unique()) == {False, True}:\n",
    "        df.loc[df[col] == True, col] = 1\n",
    "        df.loc[df[col] == False, col] = 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].astype(\"int\")\n",
    "    elif len(set(df[col].dropna().unique())) == 1:\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a profiling report\n",
    "\n",
    "Uncomment and run this cell to get a pandas profiling report. This will show nicely which features are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df.reset_index(drop=True), title=\"Pandas Profiling Report\")\n",
    "# profile.to_file(\"pandas_report1.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last columns of dtype object\n",
    "\n",
    "The last three columns of dtype object consist of 2 non-boolean features and 1 column with the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "len(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name: publisher\n",
      "number of unique values: 51\n",
      "unique values: ['Trans Tech' 'SAGE Publications, Inc' nan 'SAGE' 'John Wiley & Sons'\n",
      " 'Rockport Publishers' 'Laurence King Publishing' 'Wiley'\n",
      " 'Routledge, an imprint of the Taylor & Francis Group'\n",
      " 'Bloomsbury Academic' 'Taylor & Francis' 'Island Press' 'Routledge'\n",
      " 'BirkhÃ¤user' 'Earthscan co-published with RIBA Publishing'\n",
      " 'Routledge/Taylor& Francis Group' 'United Nations' 'the MIT Press'\n",
      " 'Edition Detail' 'Getty Conservation Institute'\n",
      " 'The Getty Conservation Institute' 'Cultural Heritage Agency'\n",
      " 'TU Delft - Heritage & Architecture' 'Univ.-Bibl.'\n",
      " 'Technische Universiteit Eindhoven, Faculteit Bouwkunde]' 'ICOMOS'\n",
      " 'Taylor and Francis' 'Princeton Architectural Press' 'BirkhaÌˆuser'\n",
      " 'Wiley-Blackwell' 'John Wiley & Sons, Incorporated.' 'Birkhauser'\n",
      " 'Metropolitan Books, Henry Holt and Co.'\n",
      " 'TU Delft, Heritage & Architecture' 'Penguin Books' 'TU Delft'\n",
      " 'De Gruyter' 'Ios Press' 'VSSD' 'Routledge Taylor & Francis Group'\n",
      " 'AEI Press' 'Springer'\n",
      " 'Erasmus Research Institute of Management, Erasmus University Rotterdam'\n",
      " 'Cambridge University Press' 'John Wiley & Sons Inc.' 'Wiley & Sons'\n",
      " 'World Intellectual Property Organization' 'Pearson Education Limited'\n",
      " 'Mosaic Business Publishers' 'VU University Press' 'CRC Press']\n",
      "number of null values: 1209\n",
      "----------------------\n",
      "column name: openaccesslink\n",
      "number of unique values: 62\n",
      "unique values: [nan\n",
      " 'https://res.mdpi.com/d_attachment/sustainability/sustainability-12-00926/article_deploy/sustainability-12-00926-v2.pdf'\n",
      " 'https://link.springer.com/content/pdf/10.1007/s11666-018-0798-8.pdf'\n",
      " 'https://www.tandfonline.com/doi/pdf/10.1080/2325548X.2017.1257283?needAccess=true'\n",
      " 'https://www.tandfonline.com/doi/pdf/10.1080/01919512.2016.1189292?needAccess=true'\n",
      " 'https://link.springer.com/content/pdf/10.1007/s11229-020-02869-9.pdf'\n",
      " 'http://www.econ.uzh.ch/static/wp/econwp027.pdf'\n",
      " 'https://academic.oup.com/qje/article-pdf/130/3/1067/17098026/qjv020.pdf'\n",
      " 'https://academic.oup.com/jid/article-pdf/200/7/1018/2681032/200-7-1018.pdf'\n",
      " 'https://academic.oup.com/icb/article-pdf/54/3/353/9102635/icu046.pdf'\n",
      " 'https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2435.2010.01753.x'\n",
      " 'https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2435.2012.02049.x'\n",
      " 'https://www.nature.com/articles/nature06536.pdf'\n",
      " 'https://www.frontiersin.org/articles/10.3389/fphys.2013.00044/pdf'\n",
      " 'http://oru.diva-portal.org/smash/get/diva2:1040262/FULLTEXT01'\n",
      " 'https://www.tandfonline.com/doi/pdf/10.1080/09615768.2019.1645436?needAccess=true'\n",
      " 'https://jmir.org/api/download?alt_name=resprot_v8i10e15303_app1.pdf&filename=6c3e188d6d2a0c703174fd080d52105a.pdf'\n",
      " 'https://www.mdpi.com/1660-4601/17/1/55/pdf'\n",
      " 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0088446&type=printable'\n",
      " 'https://academic.oup.com/hmg/article-pdf/13/10/993/1685422/ddh119.pdf'\n",
      " 'https://journals.plos.org/plosgenetics/article/file?id=10.1371/journal.pgen.1005373&type=printable'\n",
      " 'https://europepmc.org/articles/pmc4019668?pdf=render'\n",
      " 'http://www.plantcell.org/content/plantcell/29/4/638.full.pdf'\n",
      " 'http://www.plantphysiol.org/content/plantphysiol/173/1/771.full.pdf'\n",
      " 'https://academic.oup.com/jxb/article-pdf/66/10/2923/18044747/erv084.pdf'\n",
      " 'https://archive-ouverte.unige.ch/unige:107799/ATTACHMENT01'\n",
      " 'https://link.springer.com/content/pdf/10.1007/s10654-016-0149-3.pdf'\n",
      " 'https://www.bmj.com/content/323/7327/1450.full.pdf'\n",
      " 'https://europepmc.org/articles/pmc6089543?pdf=render'\n",
      " 'https://europepmc.org/articles/pmc5207342?pdf=render'\n",
      " 'http://wrap.warwick.ac.uk/4153/1/WRAP_Nicolini_manuscript_rtp10_--__final__with_corrections.pdf'\n",
      " 'https://dash.harvard.edu/bitstream/1/4778477/1/Wilson_TheoryEthnography.pdf'\n",
      " 'https://ro.uow.edu.au/cgi/viewcontent.cgi?article=1302&context=buspapers'\n",
      " 'https://qualitysafety.bmj.com/content/4/2/80.full.pdf'\n",
      " 'https://scholarlypublications.universiteitleiden.nl/access/item%3A3006652/view'\n",
      " 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/hex.12089'\n",
      " 'https://www.bmj.com/content/bmj/359/bmj.j4891.full.pdf'\n",
      " 'https://academic.oup.com/intqhc/article-pdf/23/5/531/5280634/mzr058.pdf'\n",
      " 'https://link.springer.com/content/pdf/10.1007%2Fs11019-016-9712-7.pdf'\n",
      " 'https://repub.eur.nl/pub/16175/puntoni_de-langhe_van-osselaer_2009.pdf'\n",
      " 'http://eprints.whiterose.ac.uk/89493/1/The%20making%20of%20the%20urban%20ent_CMR.pdf'\n",
      " 'https://www.nature.com/articles/palcomms201514.pdf'\n",
      " 'http://dspace.khazar.org/bitstream/20.500.12323/2954/1/The%20Role%20of%20Education%20Quality%20for%20Economic%20Growth.pdf'\n",
      " 'https://link.springer.com/content/pdf/10.1007/s11625-018-0582-1.pdf'\n",
      " 'http://www.scirp.org/journal/PaperDownload.aspx?paperID=8269'\n",
      " 'https://repub.eur.nl/pub/104026/RePub-109895-OA.pdf'\n",
      " 'https://pure.rug.nl/ws/files/81733365/Understanding_Customer_Experience_Throughout_the_Customer_Journey.pdf'\n",
      " 'https://www.mdpi.com/1996-1073/14/19/6384/pdf'\n",
      " 'https://repository.tudelft.nl/islandora/object/uuid%3A4c6d6fb8-553c-45be-bba3-e4159a2b9d3c/datastream/OBJ/download'\n",
      " 'https://www.tandfonline.com/doi/pdf/10.1080/22423982.2018.1454785?needAccess=true'\n",
      " 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/ppe.12792'\n",
      " 'https://juniperpublishers.com/pbsij/pdf/PBSIJ.MS.ID.555585.pdf'\n",
      " 'http://parkerlab.bio.uci.edu/publication%20attachments/2005_stutzmann_parker_129.pdf'\n",
      " 'https://academiccommons.columbia.edu/doi/10.7916/d8-2yqs-rg36/download'\n",
      " 'https://academic.oup.com/acn/article-pdf/24/1/31/10233/acn001.pdf'\n",
      " 'https://escholarship.org/content/qt9ww1p0g8/qt9ww1p0g8.pdf?t=q0ljsn'\n",
      " 'https://www.nature.com/articles/gim201373.pdf'\n",
      " 'https://www.tandfonline.com/doi/pdf/10.1080/17441692.2018.1446545?needAccess=true'\n",
      " 'https://read.dukeupress.edu/tsq/article-pdf/8/2/238/925248/238tudor.pdf'\n",
      " 'https://read.dukeupress.edu/poetics-today/article-pdf/29/1/103/458907/PT029-01-05HirschFpp.pdf'\n",
      " 'https://www.ccsenet.org/journal/index.php/ass/article/download/65942/36452'\n",
      " 'https://www.nature.com/articles/nrdp201535.pdf']\n",
      "number of null values: 1218\n",
      "----------------------\n",
      "column name: prediction\n",
      "number of unique values: 8\n",
      "unique values: ['eigen materiaal - titelindicatie' 'lange overname' 'onbekend'\n",
      " 'middellange overname' 'eigen materiaal - overig' 'korte overname'\n",
      " 'open access' 'eigen materiaal - powerpoint']\n",
      "number of null values: 0\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for col in object_cols:\n",
    "    print(f\"column name: {col}\")\n",
    "    print(f\"number of unique values: {len(df[col].unique())}\")\n",
    "    print(f\"unique values: {df[col].unique()}\")\n",
    "    print(f\"number of null values: {df[col].isna().sum()}\")\n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop openaccesslink\n",
    "\n",
    "The 'openaccesslink' feature has 60 unique values, which are uniformly distributed and only once or twice each. This feature has 95% missing values; whether this value is missing highly correlates with the value of 'isopenaccesstitle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints that are open access titles:\t\t68.\n",
      "Number of open access titles that have an open access link:\t62.\n",
      "==========================================================================\n",
      "Number of datapoints that are NOT open access titles:\t\t1212.\n",
      "Number of non open access titles that have an open access link:\t0.\n"
     ]
    }
   ],
   "source": [
    "oa = df.loc[df[\"isopenaccesstitle\"] == 1]\n",
    "print(f\"Number of datapoints that are open access titles:\\t\\t{len(oa)}.\\nNumber of open access titles that have an open access link:\\t{oa['openaccesslink'].notna().sum()}.\")\n",
    "\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "not_oa = df.loc[df[\"isopenaccesstitle\"] == 0]\n",
    "print(f\"Number of datapoints that are NOT open access titles:\\t\\t{len(not_oa)}.\\nNumber of non open access titles that have an open access link:\\t{not_oa['openaccesslink'].notna().sum()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"openaccesslink\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop publisher\n",
    "\n",
    "The 'publisher' feature is highly correlated with many features, such as wordcount, contains_researchgate, Words_more_300pp and several others. It also has 95% missing values and 38 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"publisher\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model\n",
    "\n",
    "### High correlation\n",
    "\n",
    "There are many features with high correlation. Since tree-based models are not so sensitive to this, let's train XGBoost on our data. This model achieves both accuracy and F1 score of 0.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158, 30)\n",
      "[[1.30000e+01 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.35151e+05 4.14000e+02 0.00000e+00 0.00000e+00 1.34000e+02 1.00000e+01\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [7.43790e+04 1.94000e+02 0.00000e+00 0.00000e+00 1.94000e+02 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(\"prediction\", axis=\"columns\").to_numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158,)\n",
      "[2 4 4]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y = label_encoder.fit_transform(df[\"prediction\"])\n",
    "\n",
    "print(y.shape)\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prediction\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "        eigen materiaal - overig       0.86      1.00      0.92        18\n",
      "    eigen materiaal - powerpoint       1.00      1.00      1.00        26\n",
      "eigen materiaal - titelindicatie       1.00      1.00      1.00        52\n",
      "                  korte overname       1.00      0.93      0.97        60\n",
      "                  lange overname       1.00      0.97      0.99        40\n",
      "            middellange overname       1.00      0.97      0.99       113\n",
      "                        onbekend       0.83      1.00      0.91        24\n",
      "                     open access       1.00      1.00      1.00        15\n",
      "\n",
      "                        accuracy                           0.98       348\n",
      "                       macro avg       0.96      0.99      0.97       348\n",
      "                    weighted avg       0.98      0.98      0.98       348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "predictions = xgb_model.predict(x_test)\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_, labels=np.unique(y_train))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With K-fold\n",
    "\n",
    "Use K-fold to confirm that the accuracy and F1 is actually that high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827288428324698\n",
      "0.9800396079006833\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    predictions = xgb_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative classifiers\n",
    "\n",
    "### Train another model, an SVC, to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689119170984455\n",
      "0.966884247502869\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(scaled_x, y):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    svc_model = SVC()\n",
    "    svc_model.fit(x_train, y_train)\n",
    "    predictions = svc_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971502590673575\n",
      "0.9641153080320543\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    predictions = rf_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9835924006908462\n",
      "0.9785058462360072\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "\n",
    "accuracy_scores = 0.0\n",
    "f1_scores = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(scaled_x, y):\n",
    "    x_train, x_test = scaled_x[train_index], scaled_x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    predictions = lr_model.predict(x_test)\n",
    "    accuracy_scores += accuracy_score(y_test, predictions)\n",
    "    f1_scores += f1_score(y_test, predictions, average=\"macro\")\n",
    "\n",
    "print(accuracy_scores/6)\n",
    "print(f1_scores/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "XGBoost has another benefit: it is straightforward to retrieve feature importance scores. Let's take a look at those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df.drop(\"prediction\", axis=\"columns\").columns.to_numpy()\n",
    "feature_importance_scores = xgb_model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 5 highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_10Pagecount50,   0.3867165446281433\n",
      "PPT_in_name,   0.08829636126756668\n",
      "isopenaccesstitle,   0.05646290257573128\n",
      "DOI_in_OA,   0.12333004176616669\n",
      "keyword_creator,   0.05074840039014816\n"
     ]
    }
   ],
   "source": [
    "top_five_indices = np.argpartition(feature_importance_scores, (-5, -1))[-5:]\n",
    "top_five_scores = feature_importance_scores[top_five_indices][::-1]\n",
    "top_five_names = feature_names[top_five_indices][::-1]\n",
    "\n",
    "for name, score in zip(top_five_names, top_five_scores):\n",
    "    print(f\"{name},   {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score is zero\n",
    "\n",
    "Some of the features have importance scores of 0. When we leave them out, we get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incollection\n",
      "jstor\n",
      "wordcount_o\n",
      "Contains_DOI\n",
      "Kleiner_10_paginas\n",
      "Contains_sciencemag\n",
      "Pagecount_bigger_50\n",
      "Contains_to_appear_in\n",
      "Contains_recommended_citation\n"
     ]
    }
   ],
   "source": [
    "zero_score_indices = np.argwhere(feature_importance_scores == 0).flatten()\n",
    "zero_score_features = feature_names[zero_score_indices]\n",
    "\n",
    "for feature in zero_score_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158, 21)\n",
      "[[1.30000e+01 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.35151e+05 4.14000e+02 0.00000e+00 1.34000e+02 1.00000e+01 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00]\n",
      " [7.43790e+04 1.94000e+02 0.00000e+00 1.94000e+02 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "features_to_remove = list(zero_score_features)\n",
    "features_to_remove.append(\"prediction\")\n",
    "\n",
    "x = df.drop(features_to_remove, axis=\"columns\").to_numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "        eigen materiaal - overig       0.86      1.00      0.92        18\n",
      "    eigen materiaal - powerpoint       1.00      1.00      1.00        26\n",
      "eigen materiaal - titelindicatie       1.00      1.00      1.00        52\n",
      "                  korte overname       1.00      0.93      0.97        60\n",
      "                  lange overname       1.00      0.97      0.99        40\n",
      "            middellange overname       1.00      0.97      0.99       113\n",
      "                        onbekend       0.83      1.00      0.91        24\n",
      "                     open access       1.00      1.00      1.00        15\n",
      "\n",
      "                        accuracy                           0.98       348\n",
      "                       macro avg       0.96      0.99      0.97       348\n",
      "                    weighted avg       0.98      0.98      0.98       348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb_model.predict(x_test)\n",
    "\n",
    "report = classification_report(y_test, predictions, target_names=label_encoder.classes_)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054e63ccd0723eba59e4e775f028e662383a4d3e051ddb13b43bfc67a74f1731"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
